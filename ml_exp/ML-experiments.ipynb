{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6515eff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, Lars\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beabe7e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dff1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"s3://ai-diennea/data/export_wonkit_20210630102441.csv.gz\")\n",
    "# convert datetime format\n",
    "data['EVENT.DATE'] = pd.to_datetime(data['EVENT.DATE'], format='%Y/%m/%d %H:%M')\n",
    "# add the day of the week column\n",
    "day_of_week = []\n",
    "for i in range(len(data)):\n",
    "    day_of_week.append(data[\"EVENT.DATE\"][i].day_name())\n",
    "data['day_of_week'] = pd.DataFrame(day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "150c9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_open_hour_range = 36\n",
    "open_click_hour_range = 24\n",
    "\n",
    "def exp_decay_fit_eval(x, sent_open_hour_range):\n",
    "    '''Return a value from 0 to 1 following an exponential decreasing function.'''\n",
    "    if x < 0:\n",
    "        x = (60*24)+x\n",
    "    if x > sent_open_hour_range*60:\n",
    "        return .0\n",
    "    return math.exp(90*((-math.log(2)/(sent_open_hour_range*60))*x) + math.log(2))/2\n",
    "\n",
    "def get_all_indexes(hash_mex, hash_contact, data):\n",
    "    '''Given the hash message, hash contact and raw data, return the indexes\n",
    "    for the hash message and hash contact in the raw data.Ã¹'''\n",
    "    return data.index[(data['HashMessaggio'] == hash_mex) & (data['HashContatto'] == hash_contact)]\n",
    "\n",
    "\n",
    "def from_min_to_hour_and_min(mins):\n",
    "    '''Given the minutes, return a string that represents the hour and minutes.'''\n",
    "    hours = int(round(mins)) // 60\n",
    "    minutes = int(round(mins)) % 60\n",
    "    return \"{}:{}\".format(hours, minutes)\n",
    "\n",
    "    \n",
    "def compute_fitSA_evaluation(hash_mex, hash_contact, sent_open_hour_range, data, sent_pred, never_opened=True):\n",
    "    '''Given the hash message, hash contact, raw data and the predicted sent hour,\n",
    "    return the fitSA for that contact and message.'''\n",
    "    sent_pred = from_min_to_hour_and_min(sent_pred)\n",
    "    df2 = data[(data['HashMessaggio'] == hash_mex)]\n",
    "    df3 = df2[(df2['HashContatto'] == hash_contact)]\n",
    "    df4 = df3[(df3['EVENT.TYPE'] == 'Open')]\n",
    "    opens = list(df4['EVENT.DATE'])\n",
    "    df5 = df3[(df3['EVENT.TYPE'] == 'Click')]\n",
    "    clicks = list(df5['EVENT.DATE'])\n",
    "    df6 = df3[(df3['EVENT.TYPE'] == 'Sent')]\n",
    "    sents = list(df6['EVENT.DATE'])\n",
    "    \n",
    "    oldest = None\n",
    "    if opens != []:\n",
    "        for i in opens:\n",
    "            if oldest is None:\n",
    "                oldest = i\n",
    "            elif i < oldest:\n",
    "                oldest = i\n",
    "    elif clicks != []:\n",
    "        for i in clicks:\n",
    "            if oldest is None:\n",
    "                oldest = i\n",
    "            elif i < oldest:\n",
    "                oldest = i\n",
    "    else: # this means that the mail has never been opened/clicked\n",
    "        if never_opened == True:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    giorni_di_differenza_tra_real_open_and_real_sent = (oldest.year*12*30 + oldest.month*30 + oldest.day) - (sents[0].year*12*30 + sents[0].month*30 + sents[0].day)\n",
    "    oldest = str(oldest.hour) +\":\"+ str(oldest.minute)\n",
    "    oldest = pd.to_datetime(oldest, format='%H:%M')\n",
    "    sent_pred = pd.to_datetime(sent_pred, format='%H:%M')\n",
    "    # compute minutes of the distance between sent-open/sent-click\n",
    "    mins = ((oldest - sent_pred).seconds//3600)*60 + ((oldest - sent_pred).seconds//60)%60\n",
    "    if giorni_di_differenza_tra_real_open_and_real_sent > 0:\n",
    "        mins = mins + (giorni_di_differenza_tra_real_open_and_real_sent*60*24)\n",
    "    return exp_decay_fit_eval(mins, sent_open_hour_range)\n",
    "\n",
    "def compute_fitSC_evaluation(hash_mex, hash_contact, open_click_hour_range, data, sent_pred, never_opened=True):\n",
    "    '''Given the message, the hash contact and the data (raw data), return the fitAC\n",
    "    for that hash message and hash contact.'''\n",
    "    sent_pred = from_min_to_hour_and_min(sent_pred)\n",
    "    df2 = data[(data['HashMessaggio'] == hash_mex)]\n",
    "    df3 = df2[(df2['HashContatto'] == hash_contact)]\n",
    "    df4 = df3[(df3['EVENT.TYPE'] == 'Click')]\n",
    "    clicks = list(df4['EVENT.DATE'])\n",
    "    df5 = df3[(df3['EVENT.TYPE'] == 'Sent')]\n",
    "    sents = list(df5['EVENT.DATE'])\n",
    "    \n",
    "    oldest_click = None\n",
    "\n",
    "    if clicks == []: # covers cases when a message is sent and is never open and never clicked\n",
    "        if never_opened == True:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        for i in clicks: # get oldest click\n",
    "            if oldest_click is None:\n",
    "                oldest_click = i\n",
    "            elif i < oldest_click:\n",
    "                oldest_click = i\n",
    "    giorni_di_differenza_tra_real_click_and_real_sent = (oldest_click.year*12*30 + oldest_click.month*30 + oldest_click.day) - (sents[0].year*12*30 + sents[0].month*30 + sents[0].day)\n",
    "    # compute minutes of the distance between sent pred-click\n",
    "    oldest_click = str(oldest_click.hour) +\":\"+ str(oldest_click.minute)\n",
    "    #print(oldest_click)\n",
    "    oldest_click = pd.to_datetime(oldest_click, format='%H:%M')\n",
    "    sent_pred = pd.to_datetime(sent_pred, format='%H:%M')\n",
    "    # compute minutes of the distance between sent-open/sent-click\n",
    "    mins = ((oldest_click - sent_pred).seconds//3600)*60 + ((oldest_click - sent_pred).seconds//60)%60\n",
    "    if giorni_di_differenza_tra_real_click_and_real_sent > 0:\n",
    "        mins = mins + (giorni_di_differenza_tra_real_click_and_real_sent*60*24)\n",
    "    return exp_decay_fit_eval(mins, sent_open_hour_range)\n",
    "\n",
    "def split_train_test_by_lifetime(X, df, data, test_size, random_seed):\n",
    "    d7 = {}\n",
    "    for i in data[\"HashContatto\"].unique():\n",
    "        if i not in d7:\n",
    "            d7[i] = []\n",
    "    for i in range(len(data)):\n",
    "        if \"nan\" not in str(data[\"EVENT.DATE\"][i]) and (str(data[\"EVENT.TYPE\"][i]) == 'Open' or str(data[\"EVENT.TYPE\"][i]) == 'Click'):\n",
    "            d7[data[\"HashContatto\"][i]].append(data[\"EVENT.DATE\"][i])\n",
    "    # Here I merge in the same category (assign 0 days) who never opened with the users that opened just once\n",
    "    for i in data[\"HashContatto\"].unique():\n",
    "        if len(d7[i]) == 0 or len(d7[i]) == 1:\n",
    "            d7[i] = 0 # 0 days as lifetime\n",
    "        else:\n",
    "        # retain newest and oldest date\n",
    "            newest_date = d7[i][0] # get the first date\n",
    "            oldest_date = d7[i][0] # get the first date\n",
    "            for j in d7[i]:\n",
    "                if j > newest_date:\n",
    "                    newest_date = j\n",
    "                if j < oldest_date:\n",
    "                    oldest_date = j\n",
    "            # assign the lifetitme for the contact i\n",
    "            d7[i] = (newest_date - oldest_date).days\n",
    "    df['Lifetime'] = 0\n",
    "    for i in range(len(df)):\n",
    "        df.loc[i, 'Lifetime'] = d7[df['HashContatto'][i]]\n",
    "    lt = df['Lifetime'].to_numpy()\n",
    "    zero = []\n",
    "    today = []\n",
    "    between = []\n",
    "    for i in range(len(lt)):\n",
    "        if lt[i] == 0:\n",
    "            zero.append(i)\n",
    "        elif lt[i] >= 320: # TODO: here I assume that a user still open today whether his lifetime is greater than or equal than 320 (it means that the last time he opened is 1 month ago)\n",
    "            today.append(i)\n",
    "        else:\n",
    "            between.append(i)\n",
    "            \n",
    "    random.Random(random_seed).shuffle(zero) # 39%\n",
    "    random.Random(random_seed).shuffle(today) # 17%\n",
    "    random.Random(random_seed).shuffle(between) # 43%\n",
    "    \n",
    "    percentage_zero_train = round(len(zero) - (test_size * len(zero)))\n",
    "    percentage_today_train = round(len(today) - (test_size * len(today)))\n",
    "    percentage_between_train = round(len(between) - (test_size * len(between)))\n",
    "    \n",
    "    train_indexes_zero = zero[:percentage_zero_train]\n",
    "    test_indexes_zero = zero[percentage_zero_train:]\n",
    "\n",
    "    train_indexes_today = today[:percentage_today_train]\n",
    "    test_indexes_today = today[percentage_today_train:]\n",
    "\n",
    "    train_indexes_between = between[:percentage_between_train]\n",
    "    test_indexes_between = between[percentage_between_train:]\n",
    "    \n",
    "    X_train = X.iloc[train_indexes_zero + train_indexes_today + train_indexes_between, :]\n",
    "    y_train = df.iloc[train_indexes_zero + train_indexes_today + train_indexes_between, :]['Label']\n",
    "    X_test = X.iloc[test_indexes_zero + test_indexes_today + test_indexes_between, :]\n",
    "    y_test = df.iloc[test_indexes_zero + test_indexes_today + test_indexes_between, :]['Label']\n",
    "    \n",
    "    df_train = df.iloc[train_indexes_zero + train_indexes_today + train_indexes_between, :]\n",
    "    df_test = df.iloc[test_indexes_zero + test_indexes_today + test_indexes_between, :]\n",
    "    return X_train, X_test, y_train, y_test, df_train, df_test    \n",
    "\n",
    "\n",
    "def count_mins(df, i, preds):\n",
    "    sent_gt = from_min_to_hour_and_min(df['Label'][i]*24*60)\n",
    "    sent_pred2 = from_min_to_hour_and_min(preds[i])\n",
    "    sent_gt = pd.to_datetime(sent_gt, format='%H:%M')\n",
    "    sent_pred2 = pd.to_datetime(sent_pred2, format='%H:%M')\n",
    "    mins = ((sent_pred2 - sent_gt).days*24*60) + ((sent_pred2 - sent_gt).seconds//3600)*60 + ((sent_pred2 - sent_gt).seconds//60)%60\n",
    "    return mins \n",
    "def evaluate(df, X, data, sent_open_hour_range, preds, never_opened=True):\n",
    "    '''Given the prediction of the model \"preds\" returns:\n",
    "    - how many fitSA are better than the ground truth fitSA\n",
    "    - how many fitSA are equal than the ground truth fitSA\n",
    "    - how many fitSA are worse than the ground truth fitSA.\n",
    "    If never_opened == True, then consider also the sent mails that have never been opened. Not otherwise.\n",
    "    '''\n",
    "    # from [0, 1] to mins\n",
    "    for i in range(len(preds)):\n",
    "        preds[i] *= 24*60 # this 24*60 is requierd to convert mins from [0, 1] into real mins\n",
    "    # get fitSA using the predicted sent\n",
    "    fitSA_preds = []\n",
    "    fitSC_preds = []\n",
    "    for i in range(len(df)):\n",
    "        fitSA_preds.append(compute_fitSA_evaluation(df['HashMessaggio'][i], df['HashContatto'][i], sent_open_hour_range, data, preds[i], never_opened=never_opened))\n",
    "        fitSC_preds.append(compute_fitSC_evaluation(df['HashMessaggio'][i], df['HashContatto'][i], sent_open_hour_range, data, preds[i], never_opened=never_opened))\n",
    "    \n",
    "    total_mex = len(fitSA_preds)\n",
    "    predicted_sent_better_usual_sent = 0\n",
    "    predicted_sent_equal_usual_sent = 0\n",
    "    predicted_sent_worst_usual_sent = 0\n",
    "    \n",
    "    mins_better = []\n",
    "    mins_worst = []\n",
    "    \n",
    "    if never_opened == True:\n",
    "        for i in range(total_mex):\n",
    "            if fitSA_preds[i] > X.loc[i, 'fitSA']:\n",
    "                predicted_sent_better_usual_sent += 1\n",
    "                mins_better.append(count_mins(df, i, preds))\n",
    "            elif fitSA_preds[i] == X.loc[i, 'fitSA']:\n",
    "                predicted_sent_equal_usual_sent += 1\n",
    "            elif fitSC_preds[i] > X.loc[i, 'fitAC']:\n",
    "                predicted_sent_better_usual_sent += 1\n",
    "                mins_better.append(count_mins(df, i, preds))\n",
    "            elif fitSC_preds[i] == X.loc[i, 'fitAC']:\n",
    "                predicted_sent_equal_usual_sent += 1\n",
    "            else:\n",
    "                predicted_sent_worst_usual_sent += 1 # case fitSC predetta < fitAC reale\n",
    "                mins_worst.append(count_mins(df, i, preds))\n",
    "        return predicted_sent_better_usual_sent/total_mex, predicted_sent_equal_usual_sent/total_mex, predicted_sent_worst_usual_sent/total_mex, [sum(mins_better)/len(mins_better), sum(mins_worst)/len(mins_worst)]\n",
    "    else:\n",
    "        total_mex_different_from_minus_one = len([i for i in fitSA_preds if i > -1])\n",
    "        total_mex_different_from_minus_one2 = len([i for i in fitSC_preds if i > -1])\n",
    "        print(total_mex_different_from_minus_one)\n",
    "        print(total_mex_different_from_minus_one2)\n",
    "        for i in range(total_mex):\n",
    "            if fitSA_preds[i] != -1 and fitSA_preds[i] > X.loc[i, 'fitSA']:\n",
    "                predicted_sent_better_usual_sent += 1\n",
    "                mins_better.append(count_mins(df, i, preds))\n",
    "                print(\"1\")\n",
    "            elif fitSA_preds[i] != -1 and fitSA_preds[i] == X.loc[i, 'fitSA']:\n",
    "                print(\"2\")\n",
    "                predicted_sent_equal_usual_sent += 1\n",
    "            elif fitSC_preds[i] != -1 and fitSC_preds[i] > X.loc[i, 'fitAC']:\n",
    "                print(\"3\")\n",
    "                predicted_sent_better_usual_sent += 1\n",
    "                mins_better.append(count_mins(df, i, preds))\n",
    "            elif fitSC_preds[i] != -1 and fitSC_preds[i] == X.loc[i, 'fitAC']:\n",
    "                print(\"4\")\n",
    "                predicted_sent_equal_usual_sent += 1\n",
    "            elif (fitSA_preds[i] != -1 and fitSA_preds[i] < X.loc[i, 'fitSA']) and (fitSC_preds[i] != -1 and fitSC_preds[i] < X.loc[i, 'fitSC']):\n",
    "                predicted_sent_worst_usual_sent += 1# TODO: creare istogramma dove discretizzi per minuto (raggruppo) e faccio media delle percentuali (tra sent e open, provare a vedere cosa acccade anche tra open e click)\n",
    "                mins_worst.append(count_mins(df, i, preds))\n",
    "                print(\"5\")\n",
    "            print(mins_better)\n",
    "            print(mins_worst)\n",
    "            return predicted_sent_better_usual_sent/total_mex_different_from_minus_one, predicted_sent_equal_usual_sent/total_mex_different_from_minus_one, predicted_sent_worst_usual_sent/total_mex_different_from_minus_one, [sum(mins_better)/len(mins_better), sum(mins_worst)/len(mins_worst)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5618f",
   "metadata": {},
   "source": [
    "## Algoritmi di learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ffcd8",
   "metadata": {},
   "source": [
    "## Least Angle Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "212834e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"s3://ai-diennea/data/df_90.csv\")\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "X = pd.read_csv(\"s3://ai-diennea/data/X_90.csv\")\n",
    "X = X.drop(['Unnamed: 0'], axis=1)\n",
    "y = pd.read_csv(\"s3://ai-diennea/data/y_90.csv\")\n",
    "y = y.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0ececec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.058909594948405974, 0.9252271677190821, 0.015863237332511937, [43.169934640522875, -12.339805825242719])\n"
     ]
    }
   ],
   "source": [
    "for i in [0.2]:    \n",
    "    # train set\n",
    "    df_train, df_test = train_test_split(df, test_size=i, random_state=42)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    # test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    model = Lars(n_nonzero_coefs=1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test_fit = X_test.copy()\n",
    "    X_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    X_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = model.predict(X_test_fit)\n",
    "\n",
    "    print(evaluate(df_test, X_test, data, sent_open_hour_range, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a1df6b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3060\n",
      "334\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-82249bb79205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_open_hour_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-174-3921eef33d5f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(df, X, data, sent_open_hour_range, preds, never_opened)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmins_better\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmins_worst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_sent_better_usual_sent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_mex_different_from_minus_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_sent_equal_usual_sent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_mex_different_from_minus_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_sent_worst_usual_sent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_mex_different_from_minus_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmins_better\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmins_better\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmins_worst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmins_worst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for i in [0.2]:    \n",
    "    # train set\n",
    "    df_train, df_test = train_test_split(df, test_size=i, random_state=42)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    # test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    model = Lars(n_nonzero_coefs=1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test_fit = X_test.copy()\n",
    "    X_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    X_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = model.predict(X_test_fit)\n",
    "\n",
    "    print(evaluate(df_test, X_test, data, sent_open_hour_range, preds, never_opened=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6faa4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: with 90 non entra in nessuna funzione.. forse troppo? to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc7d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4cafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73131a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be88cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720f6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808ecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec226a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60cc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46145a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66f6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3bc9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151dca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1f7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a6e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dffc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d91b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08011dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-193, -108, 4, 37, 71, -242, 71, 36, 44, -137, 25, 71, -109, 21, -137, 65, 71, 4, 123, -137, 64, -135, 67, 68, 67, 38, -135, 245, -137, 65, -137, 45, 71, -135, 21, 245, 38, 38, 4, -137, -137, 245, 25, 68, -135, 21, 4, -137, 38, 68, -137, 69, -137, 25, 44, 68, 65, 4, 67, 68, 69, -193, 44, -192, 4, -121, -137, 68, -193, 67, 123, 71, 67, 67, 69, 67, 71, -137, 123, 4, -192, -137, 25, 38, 44, 45, 4, 21, 25, 38, -137, 4, -137, 4, 25, 245, -137, 68, 4, -242, -193, 68, 67, -109, -241, -137, 67, -108, -141, 25, -137, -135, -109, 45, 71, 69, -109, 69, 65, -137, 68, 69, 71, 71, 25, 25, 67, 21, -140, 68, -121, 38, 38, 44, 71, 69, -141, 4, 71, 245, 21, -193, 67, -121, -109, 68, 65, -193, -242, 71, 71, 65, -135, 69, 25, 70, 68, 71, 68, -137, 21, 69, 68, -137, -109, 69, -140, 65, -121, 34, 69, 21, 4, -109, -241, -243, -141, 65, 21, 45, -140, -121, -109, 71, 25, 69, 21, -109, 69, 25, 25, -141, 123, 21, 25, 32, 21, 69, 68, 38, 71, 4, 38, 71, 69, 21, 45, -137, 68, 65, 68, -135, 71, 71, 67, -193, 68, 21, 4, 4, 38, 69, -121, 38, 68, -193, -193, 38, 67, 71, 68, 4, 21, 21, 4, 21, 70, 67, 45, 38, 71, 37, 44, 38, -121, 69, 45, 71, -109, 21, 21, 4, 45, -137, 26, 4, -137, 68, 244, 38, -141, -137, 67, 25, 68, 70, 67, 45, -137, -137, 123, 71, 69, 45, 25, 4, 25, 69, 4, 25, 44, 25, 69, 34, 4, 65, 4, 66, 4, -137, 38, 21, -137, 25, 37, 64, 68, -109, 21, 71, 67, -121, 38, 45, 45, 38, 68, 70, 69, 25, 44, 25, 245, 68, 4, 4, 69, 24, 4, 67, 38, -137, -241, -141, 25, 38, 4, 69, 4, -109, 21, -137, 245, 44, 45, 25, 37, 4, -242, 69, 45, 69, 123, -108, 67, 25, 68, 69, 21, 70, 25, -140, 67, 21, 38, 4, 21, 69, 4, 67, 25, 71, 21, 26, 245, 69, 71, 71, -193, 68, 21, 44, 68, 65, -137, 21, 45, 4, -243, 69, 123, 25, 68, 38, -137, -141, 25, -137, -137, 71, 67, 67, 71, 38, 21, 25, -193, 4, 71, 71, -121, 245, 25, 67, 69, 45, 244, -135, 45, -135, 38, 35, 71, 68, 25, 38, 69, 25, 67, 37, 244, 25, 4, 25, 67, 38, 68, 25, 38, 21, -192, 67, 71, 68, 38, 21, -121, -121, -193, 25, 25, 67, 38, -137, 68, 244, -135, 68, 38, 65, -135, 71, 71, -192, 21, 38, 71, -137, -243, 245, 25, 68, -192, 68, 67, 38, 4, 21, 4, 65, -121, 21, -121, 24, -141, -135, 70, -243, 25, 38, 25, 67, -137, 21, 69, 71, 70, 25, -140, 69, 21, -135, -137, 71, -192, 25, -135, 26, 123, 71, 245, 67, 71, 68, 123, -241, 66, 69, 67, 67, 25, -193, 25, 64, 70, -193, -137, -109, 44, 38, 123, 45, 67, 68, 21, 38, 21, -137, 65, -137, 25, -121, 37, 4, 64, 69, -121, 38, -121, 21, -137, 67, -242, -137, -108, 38, -193, -137, 69, 71, 25, 21, 38, 38, 38, 68, 68, 69, -109, -193, 4, -137, 65, 67, 68, 38, 245, 67, -109, 245, 69, 69, 4, 68, -137, 25, 38, -135, -193, 21, -192, 65, 67, -109, 68, 245, -121, -137, -135, 4, 67, 67, 38, -137, 21, -137, 44, 68, -109, -137, 25, 21, 65, 71, 68, -121, -135, 38, 45, 69, 37, 25, -192, 69, 25, 123, 38, -193, 21, 67, -141, 25, -137, 68, 25, 69, -135, -140, 38, 45, 67, -109, 21, 71, 68, -243, 21, 38, 44, -193, 4, 123, 67, 64, 69, 67, 69, 67, 4, -193, -121, 38, 44, 245, 38, 65, -109, 69, -121, 25, 65, 69, 71, 4, 25, -137, 67, 68, -135, 21, -193, 69, 69, 67, 25, -121, -141, 25, 25, -193, 67, 44, -109, -135, -137, -241, 4, 64, 68, 123, 44, 68, -135, 67, 123, -241, 25, 25, 67, -242, 67, 38, 71, 67, 21, 69, 36, 38, -137, -192, 67, 26, 68, -137, 21, 69, -241, -242, 38, 69, 245, 245, -193, 37, 71, 71, 68, 68, 69, 66, 245, -109, 69, 68, 67, 67, 68, 68, 25, -193, 71, 4, 38, 21, 68, -241, 123, -193, -241, 67, 67, 45, 25, 64, 71, -193, 68, -141, 38, 38, 67, 66, 38, 64, -135, 4, 64, 21, 38, 69, 68, 37, -137, -193, 69, 25, -193, 67, 25, 25, -192, 69, 67, 38, -192, 21, 123, 25, 70, 64, 44, 21, 67, 69, -137, 68, -193, 4, 21, 25, 38, 65, -121, -137, -193, 4, -193, 45, 38, 21, 21, 68, 245, 21, 65, 21, 38, 44, -135, 245, 68, 69, -121, 4, 245, 69, 67, -137, 71, 45, 71, 71, -137, -135, -137, 38, 21, 25, 68, 68, 123, 245, 68, -108, -109, 67, 44, 4, 21, -241, -193, 245, 25, 67, 45, 71, 21, 67, 71, 71, -193, 71, 64, -141, 38, 67, 21, 67, -137, 69, 4, 69, -121, -137, 68, 25, 67, 21, 71, 123, 44, 4, 67, 67, 70, 38, 67, 36, 123, -121, 245, -135, 4, 244, -193, 245, 123, -137, 38, 68, 68, -193, 71, -121, 4, 21, -141, -192, 245, -108, 68, 38, 123, -109, -109, -135, 71, -121, 68, 68, 25, 38, 21, -109, -193, 244, 245, -135, 70, 67, 69, 4, 66, 67, 69, -140, -241, 65, 4, -141, 67, 67, 38, 68, -140, 44, 67, -140, 69, 67, 69, -109, 123, 64, 21, 38, -140, 38, 69, -137, 245, 45, 123, 68, 67, 4, 25, 69, 45, 66, 71, 45, 44, 65, 24, 44, 68, 68, -137, -135, -193, -121, 69, 66, -109, 21, 25, 21, 38, 123, 245, 4, 44, -140, 67, -121, 4, -137, -121, -135, 69, 69, 68, 45, -192, 25, 67, 69, 71, 21, 25, 38, 4, 25, 68, 38, 67, 25, 71, -137, 25, 21, 38, 67, -137, 245, 65, 38, -137, 45, -109, -140, 67, 25, 68, 44, -121, -242, 21, 38, 69, 67, -137, 71, 35, 65, -135, 38, 45, 64, 68, -135, 71, 69, 67, 25, 69, -193, -137, 67, 71, 68, 67, 44, 21, 68, 67, 71, 4, 64, 67, 4, 69, 64, 69, 69, 25, 67, -135, 67, 69, 123, 4, 69, 25, -109, -137, 21, 68, 121, 4, 67, 71, 67, 38, 67, -193, 245, 69, -193, 45, 45, -135, 67, 38, -241, -193, 69, 67, 21, -137, 66, 66, 67, -193, 4, -137, -137, 71, 4, 4, 38, 69, -141, 4, -137, -137, 67, -137, 71, -193, 4, 69, 69, 21, 26, 69, 69, 21, 66, -137, -137, -137, 68, 245, 25, -193, 45, 69, -193, 24, 70, 71, 71, 25, 21, 38, -241, -121, 25, 68, 71, 71, 71, 4, 65, -135, 45, 4, 69, 67, 67, 69, -135, 65, 68, -140, 69, 67, 244, 21, 68, 38, 67, 38, -140, 25, 68, -137, 67, 25, -137, -121, 4, 4, 67, 25, 69, -121, 66, 71, 65, 68, 245, 45, 67, 65, 245, 21, -121, 25, 71, 71, 45, 25, 4, 69, 25, -137, -135, 68, -135, 45, -135, 45, 25, -109, -109, 4, 25, -135, -137, 25, 25, 38, -137, 37, -193, 69, 21, 71, -135, 71, 69, 65, 123, 71, 38, 25, 65, 25, 71, 38, 25, 71, -121, -141, 25, -137, 21, 71, 25, 69, -193, 4, 4, -137, 71, 38, 25, 69, -137, 25, 45, 123, 21, 26, 68, -137, -121, -137, 68, 4, 65, 245, -121, -137, 71, -140, 67, 45, 35, 69, 25, -121, 245, -193, -241, 44, 68, 25, -121, 21, 25, 69, -121, 21, 45, 66, 65, 45, 25, 69, 21, 38, -243, -243, 44, -137, -137, 21, 44, 67, 67, 4, 69, 69, 68, 4, 25, -141, 68, 69, 38, 69, 25, 36, 45, 25, -242, 70, -243, -135, -193, 31, 245, 123, 21, 44, -137, -192, 38, 67, 67, 25, -141, -137, 65, 71, 21, -137, 45, 66, 71, 67, 38, -109, -137, 68, 68, 68, 67, 68, 25, 68, 4, 67, -109, 68, 21, -193, 69, 71, 64, 65, 25, 25, 67, 38, 21, 245, 45, -241, -193, 21, 67, 69, 69, 67, 67, -137, 68, -137, 4, 4, 68, 38, 38, 123, 71, 67, -193, 38, 70, 65, 71, 67, 64, 4, 67, 68, -109, -137, -137, 65, 67, 45, 25, 71, 71, 67, -140, 68, -137, 67, 69, 25, 67, 67, -243, 25, -109, 68, 67, -242, 21, 38, 69, 25, -241, -140, 69, -193, 67, 71, 25, 67, 25, 65, 21, 4, -242, 38, 21, 35, 21, -121, -109, 21, -137, 71, 21, -137, 26, 123, 69, 21, 71, 4, 71, 71, 67, 69, 4, 69, -135, -141, 21, -121, 45, 67, 68, 37, -193, 66, 67, -137, 25, 65, 37, 65, 123, 65, 68, -109, 38, 67, 69, -121, 4, 44, 67, 41, 71, -109, -110, 45, 21, 71, 68, 25, 68, -193, 38, 4, -137, 38, -109, 45, 21, 68, 38, 67, 25, 4, 68, 21, 68, 67, 67, 71, 67, 25, -241, 70, 21, 45, 38, 21, 38, 245, 4, -193, 69, 71, 68, 25, 68, 245, 25, 65, 45, 25, 123, 38, 38, 38, 68, 21, 26, 71, 67, -109, -141, -193, -242, 25, 245, 21, -137, 68, 69, 69, 69, 69, 37, 67, -243, 68, 38, 123, 67, 67, 67, 37, 71, -137, 38, 21, 4, 71, 69, 245, -137, -121, 67, -241, 245, 69, 38, -121, 25, 69, 25, 67, 44, 68, 68, 38, 245, 21, -135, 45, 25, -135, 25, 4, 68, 67, 36, 4, 68, 67, -193, 4, 67, 69, -137, 67, 38, -137, 21, 245, 37, 4, -137, 45, -192, 71, 36, 65, 69, 67, 45, 38, 245, 67, 67, 68, 67, -135, 21, 25, 26, 21, 4, 123, 65, 69, -121, 38, 4, -241, 33, -137, -193, 67, 38, -135, -109, 44, 123, 123, 4, 69, 25, 68, 25, 21, 68, 38, 68, 21, 68, 25, 38, 21, -135, 45, 67, 69, 25, -108, 4, 69, 4, -140, 4, 68, 71, -193, 70, 68, 67, 67, 38, 4, 4, 67, 66, 25, -140, 68, 44, 64, -137, 45, 25, 38, 25, 21, -137, 70, -242, 38, 65, 25, 38, 21, 24, -137, 245, 4, 44, -135, 38, -135, 71, 71, 4, -109, -135, 245, -193, -135, 123, 35, 67, 25, 38, 21, 44, 21, 68, 68, -241, -135, 71, 25, -135, -193, 25, -135, 68, 71, 68, 4, 25, 65, 4, -121, 67, 69, 69, 71, -192, -137, -193, 123, 21, 123, -193, -241, -141, 67, 68, -137, 69, -137, 38, 71, -121, 25, 67, 4, 67, 70, 67, 4, 4, -109, 123, 69, -193, -109, -109, 37, 67, -137, -141, 25, -140, 44, 21, 65, 21, 45, 4, 25, 38, 21, -137, 38, 68, 68, -137, 69, 71, 4, 21, -137, -121, 245, 68, 67, 70, 66, 21, 38, 21, 68, 69, 21, 68, -137, 66, 69, -121, 71, -193, 45, 71, -242, 21, 245, 37, 37, 37, 71, 69, -121, 67, 69, 38, 38, 21, 70, -137, -135, 65, -137, 68, 25, 68, 67, 64, 65, 38, 38, 69, -108, 38, 71, 69, 68, 25, -135, 68, -135, -193, 68, 67, 68, 25, 21, -121, 71, 68, 68, 25, 69, 25, 26, 67, 71, 67, 38, 123, 67, 4, 69, 67, 244, 4, 38, 32, 25, 68, 69, -141, 69, 67, -121, 25, -109, 65, 67, 4, 69, 67, 25, 21, -192, 69, 71, 21, 70, 25, -121, 4, -121, 71, 69, 71, 25, -137, -108, 71, 71, 38, -192, -135, 68, -121, -140, 67, 25, -109, 21, 4, -192, 67, 44, 71, 25, 67, 68, 45, 67, 25, -137, -109, 25, 68, 123, 66, 67, 71, 71, 245, 21, 25, 69, -137, 32, 69, 25, 25, 25, 68, 38, 67, 70, 38, -193, -121, 65, 69, -193, -193, -141, 65, 4, 25, 71, 38, 71, -108, 69, 69, -137, -109, -121, 69, 69, 69, -137, 71, -137, 38, 68, 4, 4, -241, 69, 67, 70, 45, -109, 44, 65, 37, 4, -135, 67, 71, -121, -137, 68, 38, 68, 25, 67, 4, -109, -193, 123, 67, 21, 45, 64, 71, 25, -241, -192, 245, 67, -137, 71, 21, -193, 67, 69, 71, 68, 25, -141, -135, -141, 4, 67, 69, -242, 38, 21, 67, 38]\n",
      "(0.160711535499769, 0.8343600800862467, 0.0049283844139842905, [6.537613799712506, -30.5625])\n",
      "[-193, -108, 4, 37, 71, -243, 71, 36, 43, -138, 25, 71, -109, 21, -138, 65, 71, 4, 122, -138, 64, -135, 67, 68, 67, 38, -135, 245, -138, 65, -138, 44, 71, -135, 21, 245, 38, 38, 4, -138, -138, 245, 25, 68, -135, 21, 4, -138, 38, 68, -138, 69, -138, 25, 43, 68, 65, 4, 67, 68, 69, -193, 43, -193, 4, -122, -138, 68, -194, 67, 122, 71, 67, 67, 69, 67, 71, -138, 122, 4, -193, -138, 25, 38, 43, 44, 4, 21, 25, 38, -138, 4, -138, 4, 25, 245, -138, 68, 4, -243, -193, 68, 67, -109, -242, -138, 67, -108, -141, 25, -138, -135, -109, 44, 71, 69, -109, 69, 65, -138, 68, 69, 71, 71, 25, 25, 67, 21, -140, 68, -122, 38, 38, 43, 71, 69, -141, 4, 71, 245, 21, -194, 67, -122, -109, 68, 65, -193, -243, 71, 71, 65, -135, 69, 25, 70, 68, 71, 68, -138, 21, 69, 68, -138, -109, 69, -140, 65, -122, 34, 69, 21, 4, -109, -242, -244, -141, 65, 21, 44, -140, -122, -109, 71, 25, 69, 21, -109, 69, 25, 25, -141, 122, 21, 25, 32, 21, 69, 68, 38, 71, 4, 38, 71, 69, 21, 44, -138, 68, 65, 68, -135, 71, 71, 67, -193, 68, 21, 4, 4, 38, 69, -122, 38, 68, -193, -194, 38, 67, 71, 68, 4, 21, 21, 4, 21, 70, 67, 44, 38, 71, 37, 43, 38, -122, 69, 44, 71, -109, 21, 21, 4, 44, -138, 26, 4, -138, 68, 244, 38, -141, -138, 67, 25, 68, 70, 67, 44, -138, -138, 122, 71, 69, 44, 25, 4, 25, 69, 4, 25, 43, 25, 69, 34, 4, 65, 4, 66, 4, -138, 38, 21, -138, 25, 37, 64, 68, -109, 21, 71, 67, -122, 38, 44, 44, 38, 68, 70, 69, 25, 43, 25, 245, 68, 4, 4, 69, 24, 4, 67, 38, -138, -242, -141, 25, 38, 4, 69, 4, -109, 21, -138, 245, 43, 44, 25, 37, 4, -243, 69, 44, 69, 122, -108, 67, 25, 68, 69, 21, 70, 25, -140, 67, 21, 38, 4, 21, 69, 4, 67, 25, 71, 21, 26, 245, 69, 71, 71, -194, 68, 21, 43, 68, 65, -138, 21, 44, 4, -244, 69, 122, 25, 68, 38, -138, -141, 25, -138, -138, 71, 67, 67, 71, 38, 21, 25, -193, 4, 71, 71, -122, 245, 25, 67, 69, 44, 244, -135, 44, -135, 38, 35, 71, 68, 25, 38, 69, 25, 67, 37, 244, 25, 4, 25, 67, 38, 68, 25, 38, 21, -193, 67, 71, 68, 38, 21, -122, -122, -193, 25, 25, 67, 38, -138, 68, 244, -135, 68, 38, 65, -135, 71, 71, -193, 21, 38, 71, -138, -244, 245, 25, 68, -193, 68, 67, 38, 4, 21, 4, 65, -122, 21, -122, 24, -141, -135, 70, -244, 25, 38, 25, 67, -138, 21, 69, 71, 70, 25, -140, 69, 21, -135, -138, 71, -193, 25, -135, 26, 122, 71, 245, 67, 71, 68, 122, -242, 66, 69, 67, 67, 25, -193, 25, 64, 70, -193, -138, -109, 43, 38, 122, 44, 67, 68, 21, 38, 21, -138, 65, -138, 25, -122, 37, 4, 64, 69, -122, 38, -122, 21, -138, 67, -243, -138, -108, 38, -194, -138, 69, 71, 25, 21, 38, 38, 38, 68, 68, 69, -109, -194, 4, -138, 65, 67, 68, 38, 245, 67, -109, 245, 69, 69, 4, 68, -138, 25, 38, -135, -194, 21, -193, 65, 67, -109, 68, 245, -122, -138, -135, 4, 67, 67, 38, -138, 21, -138, 43, 68, -109, -138, 25, 21, 65, 71, 68, -122, -135, 38, 44, 69, 37, 25, -193, 69, 25, 122, 38, -193, 21, 67, -141, 25, -138, 68, 25, 69, -135, -140, 38, 44, 67, -109, 21, 71, 68, -244, 21, 38, 43, -193, 4, 122, 67, 64, 69, 67, 69, 67, 4, -194, -122, 38, 43, 245, 38, 65, -109, 69, -122, 25, 65, 69, 71, 4, 25, -138, 67, 68, -135, 21, -193, 69, 69, 67, 25, -122, -141, 25, 25, -193, 67, 43, -109, -135, -138, -242, 4, 64, 68, 122, 43, 68, -135, 67, 122, -242, 25, 25, 67, -243, 67, 38, 71, 67, 21, 69, 36, 38, -138, -193, 67, 26, 68, -138, 21, 69, -242, -243, 38, 69, 245, 245, -194, 37, 71, 71, 68, 68, 69, 66, 245, -109, 69, 68, 67, 67, 68, 68, 25, -193, 71, 4, 38, 21, 68, -242, 122, -193, -242, 67, 67, 44, 25, 64, 71, -193, 68, -141, 38, 38, 67, 66, 38, 64, -135, 4, 64, 21, 38, 69, 68, 37, -138, -193, 69, 25, -193, 67, 25, 25, -193, 69, 67, 38, -193, 21, 122, 25, 70, 64, 43, 21, 67, 69, -138, 68, -194, 4, 21, 25, 38, 65, -122, -138, -193, 4, -193, 44, 38, 21, 21, 68, 245, 21, 65, 21, 38, 43, -135, 245, 68, 69, -122, 4, 245, 69, 67, -138, 71, 44, 71, 71, -138, -135, -138, 38, 21, 25, 68, 68, 122, 245, 68, -108, -109, 67, 43, 4, 21, -242, -193, 245, 25, 67, 44, 71, 21, 67, 71, 71, -193, 71, 64, -141, 38, 67, 21, 67, -138, 69, 4, 69, -122, -138, 68, 25, 67, 21, 71, 122, 43, 4, 67, 67, 70, 38, 67, 36, 122, -122, 245, -135, 4, 244, -193, 245, 122, -138, 38, 68, 68, -193, 71, -122, 4, 21, -141, -193, 245, -108, 68, 38, 122, -109, -109, -135, 71, -122, 68, 68, 25, 38, 21, -109, -194, 244, 245, -135, 70, 67, 69, 4, 66, 67, 69, -140, -242, 65, 4, -141, 67, 67, 38, 68, -140, 43, 67, -140, 69, 67, 69, -109, 122, 64, 21, 38, -140, 38, 69, -138, 245, 44, 122, 68, 67, 4, 25, 69, 44, 66, 71, 44, 43, 65, 24, 43, 68, 68, -138, -135, -194, -122, 69, 66, -109, 21, 25, 21, 38, 122, 245, 4, 43, -140, 67, -122, 4, -138, -122, -135, 69, 69, 68, 44, -193, 25, 67, 69, 71, 21, 25, 38, 4, 25, 68, 38, 67, 25, 71, -138, 25, 21, 38, 67, -138, 245, 65, 38, -138, 44, -109, -140, 67, 25, 68, 43, -122, -243, 21, 38, 69, 67, -138, 71, 35, 65, -135, 38, 44, 64, 68, -135, 71, 69, 67, 25, 69, -193, -138, 67, 71, 68, 67, 43, 21, 68, 67, 71, 4, 64, 67, 4, 69, 64, 69, 69, 25, 67, -135, 67, 69, 122, 4, 69, 25, -109, -138, 21, 68, 121, 4, 67, 71, 67, 38, 67, -193, 245, 69, -194, 44, 44, -135, 67, 38, -242, -194, 69, 67, 21, -138, 66, 66, 67, -193, 4, -138, -138, 71, 4, 4, 38, 69, -141, 4, -138, -138, 67, -138, 71, -193, 4, 69, 69, 21, 26, 69, 69, 21, 66, -138, -138, -138, 68, 245, 25, -194, 44, 69, -194, 24, 70, 71, 71, 25, 21, 38, -242, -122, 25, 68, 71, 71, 71, 4, 65, -135, 44, 4, 69, 67, 67, 69, -135, 65, 68, -140, 69, 67, 244, 21, 68, 38, 67, 38, -140, 25, 68, -138, 67, 25, -138, -122, 4, 4, 67, 25, 69, -122, 66, 71, 65, 68, 245, 44, 67, 65, 245, 21, -122, 25, 71, 71, 44, 25, 4, 69, 25, -138, -135, 68, -135, 44, -135, 44, 25, -109, -109, 4, 25, -135, -138, 25, 25, 38, -138, 37, -194, 69, 21, 71, -135, 71, 69, 65, 122, 71, 38, 25, 65, 25, 71, 38, 25, 71, -122, -141, 25, -138, 21, 71, 25, 69, -193, 4, 4, -138, 71, 38, 25, 69, -138, 25, 44, 122, 21, 26, 68, -138, -122, -138, 68, 4, 65, 245, -122, -138, 71, -140, 67, 44, 35, 69, 25, -122, 245, -193, -242, 43, 68, 25, -122, 21, 25, 69, -122, 21, 44, 66, 65, 44, 25, 69, 21, 38, -244, -244, 43, -138, -138, 21, 43, 67, 67, 4, 69, 69, 68, 4, 25, -141, 68, 69, 38, 69, 25, 36, 44, 25, -243, 70, -244, -135, -193, 31, 245, 122, 21, 43, -138, -193, 38, 67, 67, 25, -141, -138, 65, 71, 21, -138, 44, 66, 71, 67, 38, -109, -138, 68, 68, 68, 67, 68, 25, 68, 4, 67, -109, 68, 21, -193, 69, 71, 64, 65, 25, 25, 67, 38, 21, 245, 44, -242, -193, 21, 67, 69, 69, 67, 67, -138, 68, -138, 4, 4, 68, 38, 38, 122, 71, 67, -194, 38, 70, 65, 71, 67, 64, 4, 67, 68, -109, -138, -138, 65, 67, 44, 25, 71, 71, 67, -140, 68, -138, 67, 69, 25, 67, 67, -244, 25, -109, 68, 67, -243, 21, 38, 69, 25, -242, -140, 69, -193, 67, 71, 25, 67, 25, 65, 21, 4, -243, 38, 21, 35, 21, -122, -109, 21, -138, 71, 21, -138, 26, 122, 69, 21, 71, 4, 71, 71, 67, 69, 4, 69, -135, -141, 21, -122, 44, 67, 68, 37, -193, 66, 67, -138, 25, 65, 37, 65, 122, 65, 68, -109, 38, 67, 69, -122, 4, 43, 67, 40, 71, -109, -110, 44, 21, 71, 68, 25, 68, -193, 38, 4, -138, 38, -109, 44, 21, 68, 38, 67, 25, 4, 68, 21, 68, 67, 67, 71, 67, 25, -242, 70, 21, 44, 38, 21, 38, 245, 4, -193, 69, 71, 68, 25, 68, 245, 25, 65, 44, 25, 122, 38, 38, 38, 68, 21, 26, 71, 67, -109, -141, -193, -243, 25, 245, 21, -138, 68, 69, 69, 69, 69, 37, 67, -244, 68, 38, 122, 67, 67, 67, 37, 71, -138, 38, 21, 4, 71, 69, 245, -138, -122, 67, -242, 245, 69, 38, -122, 25, 69, 25, 67, 43, 68, 68, 38, 245, 21, -135, 44, 25, -135, 25, 4, 68, 67, 36, 4, 68, 67, -193, 4, 67, 69, -138, 67, 38, -138, 21, 245, 37, 4, -138, 44, -193, 71, 36, 65, 69, 67, 44, 38, 245, 67, 67, 68, 67, -135, 21, 25, 26, 21, 4, 122, 65, 69, -122, 38, 4, -242, 33, -138, -193, 67, 38, -135, -109, 43, 122, 122, 4, 69, 25, 68, 25, 21, 68, 38, 68, 21, 68, 25, 38, 21, -135, 44, 67, 69, 25, -108, 4, 69, 4, -140, 4, 68, 71, -194, 70, 68, 67, 67, 38, 4, 4, 67, 66, 25, -140, 68, 43, 64, -138, 44, 25, 38, 25, 21, -138, 70, -243, 38, 65, 25, 38, 21, 24, -138, 245, 4, 43, -135, 38, -135, 71, 71, 4, -109, -135, 245, -193, -135, 122, 35, 67, 25, 38, 21, 43, 21, 68, 68, -242, -135, 71, 25, -135, -193, 25, -135, 68, 71, 68, 4, 25, 65, 4, -122, 67, 69, 69, 71, -193, -138, -193, 122, 21, 122, -193, -242, -141, 67, 68, -138, 69, -138, 38, 71, -122, 25, 67, 4, 67, 70, 67, 4, 4, -109, 122, 69, -193, -109, -109, 37, 67, -138, -141, 25, -140, 43, 21, 65, 21, 44, 4, 25, 38, 21, -138, 38, 68, 68, -138, 69, 71, 4, 21, -138, -122, 245, 68, 67, 70, 66, 21, 38, 21, 68, 69, 21, 68, -138, 66, 69, -122, 71, -194, 44, 71, -243, 21, 245, 37, 37, 37, 71, 69, -122, 67, 69, 38, 38, 21, 70, -138, -135, 65, -138, 68, 25, 68, 67, 64, 65, 38, 38, 69, -108, 38, 71, 69, 68, 25, -135, 68, -135, -193, 68, 67, 68, 25, 21, -122, 71, 68, 68, 25, 69, 25, 26, 67, 71, 67, 38, 122, 67, 4, 69, 67, 244, 4, 38, 32, 25, 68, 69, -141, 69, 67, -122, 25, -109, 65, 67, 4, 69, 67, 25, 21, -193, 69, 71, 21, 70, 25, -122, 4, -122, 71, 69, 71, 25, -138, -108, 71, 71, 38, -193, -135, 68, -122, -140, 67, 25, -109, 21, 4, -193, 67, 43, 71, 25, 67, 68, 44, 67, 25, -138, -109, 25, 68, 122, 66, 67, 71, 71, 245, 21, 25, 69, -138, 32, 69, 25, 25, 25, 68, 38, 67, 70, 38, -193, -122, 65, 69, -193, -194, -141, 65, 4, 25, 71, 38, 71, -108, 69, 69, -138, -109, -122, 69, 69, 69, -138, 71, -138, 38, 68, 4, 4, -242, 69, 67, 70, 44, -109, 43, 65, 37, 4, -135, 67, 71, -122, -138, 68, 38, 68, 25, 67, 4, -109, -193, 122, 67, 21, 44, 64, 71, 25, -242, -193, 245, 67, -138, 71, 21, -193, 67, 69, 71, 68, 25, -141, -135, -141, 4, 67, 69, -243, 38, 21, 67, 38, 25, 71, 71, 69, 21, 37, 25, 70, 71, -193, 67, -122, 38, 245, 25, 67, -122, 122, 35, 25, 67, 4, 4, 245, 245, 67, 68, -243, -138, -135, 25, 67, -135, -138, 68, 67, 4, -140, 42, 21, -135, -135, 67, 67, -135, -193, 69, -138, 67, 68, 38, 4, 69, 25, -135, 38, -193, 38, 25, 71, 68, 67, 25, -138, 38, -193, 65, -140, 25, -122, 68, 38, 71, 38, -108, -194, 69, -242, 67, 38, 69, 65, -109, 38, 71, 66, 64, 38, 71, -138, 69, 67, 4, 21, 36, -122, 69, 71, -122, 21, 69, 69, 4, 21, 21, 21, 25, 67, -109, 71, 65, 245, 67, 71, 44, 70, 68, 4, 38, 25, 25, 65, -242, -135, 245, 65, 67, 43, -140, 38, -135, 245, 25, 21, 69, 67, 38, 68, 44, 71, 71, 67, 38, 68, -141, 25, 4, 67, 68, 43, 69, -135, 25, -138, 69, -193, -193, -135, -138, 69, 68, 25, 68, 65, 71, -109, 71, -122, 244, 67, 71, 71, 245, 4, -141, 66, 21, 69, 68, -122, 71, -109, -135, 21, 21, 38, 21, -135, -138, 64, 69, 4, 38, -140, 71, 66, -141, 71, -122, 245, 25, 67, 25, 67, 21, -193, 67, 68, 38, 245, -122, 71, -193, 67, -135, 67, 68, -193, 67, 38, 44, 68, -135, 70, -138, 67, 68, 21, 38, 25, 25, -122, 38, -138, 245, 44, -109, -138, 67, 68, 71, -242, 38, -193, 35, 67, 244, 65, -138, 38, 67, -194, 38, 70, 38, 71, -122, -140, -138, -109, -141, 36, 25, 38, 71, 35, -242, 68, -140, -193, -138, 71, -138, 67, 70, -122, -140, 25, -138, 21, 25, -138, 21, 69, 71, 4, 65, 67, 67, 69, 65, 68, 69, 67, -135, 71, 42, 21, 43, 71, 67, 68, 25, 67, -242, 25, 69, 38, 67, 38, -140, -193, 25, 25, 38, 65, 67, 68, 68, 122, 67, 38, 69, -138, 65, 65, 30, -193, 69, 43, 71, 64, 34, -193, -122, -138, -109, -109, -194, 25, -138, -138, 68, 4, 25, -242, 68, 245, 4, 37, 44, 245, 38, 67, -193, 122, -135, -138, 37, 69, 69, 71, -243, 67, 25, 69, 38, 37, -194, 69, -193, 67, 71, 38, 245, 71, 44, 4, 69, 38, 64, 67, 68, 71, 67, 245, 25, 70, 44, 44, 44, 44, -193, 71, 43, 68, -140, -193, 25, 68, 69, 21, 25, 44, 25, 25, 38, 67, 67, -122, 21, 25, 21, 69, -135, -138, -194, 67, 64, 38, 25, 67, 69, -194, 25, 25, 67, -122, 71, 71, 4, -108, 69, 43, 44, -138, -109, 69, 38, 69, 67, 69, 25, 37, 68, 21, -242, 4, -138, 67, 64, 25, 68, 65, 43, -138, 44, -140, 71, 44, 21, -138, 42, 41, 68, 38, 69, 67, 69, 4, 70, 34, 4, -243, 65, 245, 66, 66, 66, -242, -138, 21, -242, 69, -138, -122, 71, 25, 68, 68, 67, 69, -138, 67, 71, 25, 71, 65, 68, -138, 69, 69, -138, 67, -193, 67, 21, -138, 37, 25, 67, 69, -242, 4, 69, -140, 67, 25, -140, 65, 68, 21, 4, 245, -138, 44, -135, -122, 64, -193, -138, 4, 71, 66, 69, 69, 68, 71, -138, 122, 65, 67, -138, 38, -138, 44, 68, -122, 68, 24, 67, 4, -194, -137, -138, -138, 69, -242, 44, 67, -122, 25, 68, -135, 122, 69, 71, 67, 21, 67, -194, 67, -243, -122, -193, 43, 21, 38, 64, 245, 4, 69, 38, 67, 245, 25, 43, 25, 68, 36, 44, 38, 38, 67, 43, -140, 68, -138, 44, 68, 71, -122, 71, 70, 67, 25, 44, 71, 25, 43, 245, 38, -193, -109, -243, -138, -122, 21, -122, 71, 38, 21, 25, 69, 69, -243, 71, 44, -193, -122, 68, -193, -138, 4, 67, 71, 71, 21, 35, 25, 245, -138, 67, -193, 65, 245, 37, 68, 69, -193, -138, 67, 21, 25, 44, 38, -122, -135, 25, 21, 69, 67, -109, 245, 41, -193, 67, -138, 38, 38, -109, 43, 65, 25, 4, 65, 67, 68, -243, 21, -193, 34, -108, 21, 25, 38, 71, 67, 71, 67, 71, 21, 21, 38, 67, -140, -193, 65, 44, 44, 38, 25, 71, 245, 67, -242, 67, 71, 65, 25, 38, 64, 37, 68, -138, 21, 25, -138, 67, 25, -108, 44, -109, 245, 71, 38, -135, 69, -193, 122, -193, 21, -109, -138, 67, 68, 25, 68, 38, 65, 21, 69, 21, -194, 66, 25, 25, 38, 43, 25, 25, 25, 67, 69, -193, 68, 25, 21, 71, 38, -138, 67, 71, 43, 25, -138, 67, -140, 21, 25, 68, -122, 65, 37, -140, 4, -138, 38, 70, 71, 21, -138, 4, 68, 67, 38, -193, -140, -193, -140, 64, 69, 65, 38, 43, -242, 21, 38, -193, 38, 4, 4, -138, 71, 43, -243, -135, 122, 4, 65, 37, 37, 25, 4, 38, 21, 71, 67, -122, 122, -193, 67, 67, 68, -138, -138, 122, -138, 44, 69, 68, 4, -109, 245, 38, 4, 38, 44, 67, 35, 69, -194, 69, 25, -135, -135, -138, 71, 21, -138, -138, 68, -193, 25, 4, 44, 67, 68, 25, -138, 68, 21, 71, 71, 38, 21, 4, 71, 71, -108, 38, 4, 25, 70, 38, 38, -135, 71, 69, 69, 245, 67, 44, 67, 38, -140, -138, 25, -135, 25, 71, 69, 4, -138, 69, 69, 24, 71, 43, 69, 21, 69, 25, 25, -138, -135, -193, -108, 44, -193, 67, -138, 44, 44, 21, -193, 245, 70, 122, 25, -193, 4, 245, 67, 67, 71, 25, 4, -194, 21, -138, -138, 4, 21, -138, 69, 71, 4, -109, -193, 43, 67, 69, -138, -138, -138, 44, 69, 69, 38, -138, 67, -138, 38, 71, 67, 69, 69, 21, 71, 69, -138, 25, 25, -194, 69, 4, 67, 69, 122, 68, -122, -109, 69, -193, 71, 25, 25, 68, 69, 65, -138, 43, -138, 66, 245, 25, 21, 36, 38, 67, 67, 122, -138, 69, 70, -141, 67, 25, 4, 71, 38, 69, 38, 44, 44, 4, 38, -138, 65, 69, 4, 26, -193, 69, -140, 21, -138, -138, 66, 65, 21, 68, 25, -193, 69, 65, 25, 69, 245, -194, 68, -193, -122, 4, 67, 68, 21, -140, 68, 21, -193, 67, 67, 67, -138, 37, 69, 68, -242, 38, -194, 69, 67, 71, 4, 25, 67, 21, 69, 67, 69, 71, 67, 25, 25, 65, -140, -135, -140, 67, 245, 25, 69, 68, 68, 71, 4, 67, 69, 69, 67, 25, 38, -122, 21]\n",
      "(0.16289337234970994, 0.8327942912880538, 0.004312336362236255, [5.71793255594075, -24.595238095238095])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c1fe17018e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_open_hour_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-b0b3f2883840>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(df, X, data, sent_open_hour_range, preds, never_opened)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mfitSC_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mfitSA_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_fitSA_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashMessaggio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashContatto'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_open_hour_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnever_opened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mfitSC_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_fitSC_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashMessaggio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashContatto'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_open_hour_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnever_opened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b0b3f2883840>\u001b[0m in \u001b[0;36mcompute_fitSA_evaluation\u001b[0;34m(hash_mex, hash_contact, sent_open_hour_range, data, sent_pred, never_opened)\u001b[0m\n\u001b[1;32m     96\u001b[0m     return the fitSA for that contact and message.'''\n\u001b[1;32m     97\u001b[0m     \u001b[0msent_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_min_to_hour_and_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashMessaggio'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhash_mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashContatto'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhash_contact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mdf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EVENT.TYPE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Open'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in [0.2, 0.3, 0.34]:    \n",
    "    # train set\n",
    "    df_train, df_test = train_test_split(df, test_size=i, random_state=42)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    # test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    model = Lars(n_nonzero_coefs=1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test_fit = X_test.copy()\n",
    "    X_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    X_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = model.predict(X_test_fit)\n",
    "\n",
    "    print(evaluate(df_test, X_test, data, sent_open_hour_range, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ceea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7324270557029178, 0.07725464190981432, 0.1903183023872679)\n",
      "(0.7330406147091109, 0.07618002195389682, 0.1907793633369923)\n",
      "(0.7336673732896511, 0.07670071304682984, 0.18963191366351898)\n"
     ]
    }
   ],
   "source": [
    "for i in [0.2, 0.3, 0.34]:    \n",
    "    # train set\n",
    "    df_train, df_test = train_test_split(df, test_size=i, random_state=42)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    # test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    model = Lars(n_nonzero_coefs=1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test_fit = X_test.copy()\n",
    "    X_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    X_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = model.predict(X_test_fit)\n",
    "\n",
    "    print(evaluate(df_test, X_test, data, sent_open_hour_range, preds, never_opened=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc5090",
   "metadata": {},
   "source": [
    "### k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ec9aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17553291625749504, 0.8221260370977399, 0.002341046644764976)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = X.copy()\n",
    "g = y.copy()\n",
    "res = []\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "for train_index, test_index in kf.split(M):\n",
    "    M_train, M_test = M.iloc[train_index], M.iloc[test_index]\n",
    "    g_train, g_test = g.iloc[train_index], g.iloc[test_index]\n",
    "    \n",
    "    model = Lars(n_nonzero_coefs=1)\n",
    "    model.fit(M_train, g_train)\n",
    "\n",
    "    M_test_fit = M_test.copy()\n",
    "    M_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    M_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = model.predict(M_test_fit)\n",
    "    my_df = df.iloc[test_index]\n",
    "    my_df.reset_index(drop=True, inplace=True)\n",
    "    M_test.reset_index(drop=True, inplace=True)\n",
    "    res.append(evaluate(my_df, M_test, data, sent_open_hour_range, preds))\n",
    "better = 0\n",
    "equal = 0\n",
    "worst = 0\n",
    "for i in range(5):\n",
    "    better += res[i][0]\n",
    "    equal += res[i][1]\n",
    "    worst += res[i][2]\n",
    "better/5, equal/5, worst/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512bf069",
   "metadata": {},
   "source": [
    "### k-fold with never_opened = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a422c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7399916349564156, 0.07358961086786106, 0.1864187541757233)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = X.copy()\n",
    "g = y.copy()\n",
    "res = []\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "for train_index, test_index in kf.split(M):\n",
    "    M_train, M_test = M.iloc[train_index], M.iloc[test_index]\n",
    "    g_train, g_test = g.iloc[train_index], g.iloc[test_index]\n",
    "    \n",
    "    model = Lars(n_nonzero_coefs=1)\n",
    "    model.fit(M_train, g_train)\n",
    "\n",
    "    M_test_fit = M_test.copy()\n",
    "    M_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    M_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = model.predict(M_test_fit)\n",
    "    my_df = df.iloc[test_index]\n",
    "    my_df.reset_index(drop=True, inplace=True)\n",
    "    M_test.reset_index(drop=True, inplace=True)\n",
    "    res.append(evaluate(my_df, M_test, data, sent_open_hour_range, preds, never_opened=False))\n",
    "better = 0\n",
    "equal = 0\n",
    "worst = 0\n",
    "for i in range(5):\n",
    "    better += res[i][0]\n",
    "    equal += res[i][1]\n",
    "    worst += res[i][2]\n",
    "better/5, equal/5, worst/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accdbdc6",
   "metadata": {},
   "source": [
    "### Lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f08a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.17010626828892653, 0.8272755274911443, 0.0026182042199291546)\n",
      "(0.1746496226705683, 0.8229888597977308, 0.002361517531700806)\n",
      "(0.17549263873159682, 0.8221064552661381, 0.002400906002265006)\n"
     ]
    }
   ],
   "source": [
    "for i in [0.20, 0.30, 0.34]:\n",
    "    X_train, X_test, y_train, y_test, df_train, df_test = split_train_test_by_lifetime(X, df, data, test_size=i, random_seed=42)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    model = model = Lars(n_nonzero_coefs=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_fit = X_test.copy()\n",
    "    X_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    X_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = model.predict(X_test_fit)\n",
    "\n",
    "    print(evaluate(df_test, X_test, data, sent_open_hour_range, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d381ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.734375, 0.07613031914893617, 0.18949468085106383)\n",
      "(0.7411764705882353, 0.07494553376906318, 0.18387799564270152)\n",
      "(0.7434273651890232, 0.0734983688351564, 0.18307426597582038)\n"
     ]
    }
   ],
   "source": [
    "for i in [0.20, 0.30, 0.34]:\n",
    "    X_train, X_test, y_train, y_test, df_train, df_test = split_train_test_by_lifetime(X, df, data, test_size=i, random_seed=42)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    model = model = Lars(n_nonzero_coefs=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_fit = X_test.copy()\n",
    "    X_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    X_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = model.predict(X_test_fit)\n",
    "\n",
    "    print(evaluate(df_test, X_test, data, sent_open_hour_range, preds, never_opened=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed38d0b5",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba53204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "# test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e71933dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               12672     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 177,537\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68403cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351c41e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36359 samples, validate on 15583 samples\n",
      "Epoch 1/10\n",
      "36359/36359 [==============================] - 4s 117us/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0126 - val_mean_absolute_error: 0.0126\n",
      "Epoch 2/10\n",
      "36359/36359 [==============================] - 3s 92us/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
      "Epoch 3/10\n",
      "36359/36359 [==============================] - 3s 91us/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0061 - val_mean_absolute_error: 0.0061\n",
      "Epoch 4/10\n",
      "36359/36359 [==============================] - 3s 90us/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0064 - val_mean_absolute_error: 0.0064\n",
      "Epoch 5/10\n",
      "36359/36359 [==============================] - 3s 90us/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0058 - val_mean_absolute_error: 0.0058\n",
      "Epoch 6/10\n",
      "36359/36359 [==============================] - 3s 92us/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 7/10\n",
      "36359/36359 [==============================] - 3s 91us/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0084 - val_mean_absolute_error: 0.0084\n",
      "Epoch 8/10\n",
      "36359/36359 [==============================] - 3s 93us/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0067 - val_mean_absolute_error: 0.0067\n",
      "Epoch 9/10\n",
      "36359/36359 [==============================] - 3s 92us/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0100 - val_mean_absolute_error: 0.0100\n",
      "Epoch 10/10\n",
      "36359/36359 [==============================] - 3s 93us/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0115 - val_mean_absolute_error: 0.0115\n",
      "(0.19929154474048977, 0.7987062990913292, 0.002002156168181118, [14.193972179289027, 6.846153846153846])\n",
      "Train on 31814 samples, validate on 13635 samples\n",
      "Epoch 1/10\n",
      "31814/31814 [==============================] - 3s 91us/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 2/10\n",
      "31814/31814 [==============================] - 3s 91us/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0048 - val_mean_absolute_error: 0.0048\n",
      "Epoch 3/10\n",
      "31814/31814 [==============================] - 3s 89us/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 4/10\n",
      "31814/31814 [==============================] - 3s 91us/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0061 - val_mean_absolute_error: 0.0061\n",
      "Epoch 5/10\n",
      "31814/31814 [==============================] - 3s 92us/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 6/10\n",
      "31814/31814 [==============================] - 3s 96us/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0055 - val_mean_absolute_error: 0.0055\n",
      "Epoch 7/10\n",
      "31814/31814 [==============================] - 3s 94us/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "Epoch 8/10\n",
      "31814/31814 [==============================] - 3s 93us/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 9/10\n",
      "31814/31814 [==============================] - 3s 92us/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
      "Epoch 10/10\n",
      "31814/31814 [==============================] - 3s 91us/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "(0.20873761486729298, 0.790338313055085, 0.0009240720776220545, [-0.8691588785046729, -15.11111111111111])\n",
      "Train on 29996 samples, validate on 12856 samples\n",
      "Epoch 1/10\n",
      "29996/29996 [==============================] - 3s 91us/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0044 - val_mean_absolute_error: 0.0044\n",
      "Epoch 2/10\n",
      "29996/29996 [==============================] - 3s 93us/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0062 - val_mean_absolute_error: 0.0062\n",
      "Epoch 3/10\n",
      "29996/29996 [==============================] - 3s 91us/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 4/10\n",
      "29996/29996 [==============================] - 3s 90us/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0048 - val_mean_absolute_error: 0.0048\n",
      "Epoch 5/10\n",
      "29996/29996 [==============================] - 3s 91us/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0047 - val_mean_absolute_error: 0.0047\n",
      "Epoch 6/10\n",
      "29996/29996 [==============================] - 3s 89us/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0060 - val_mean_absolute_error: 0.0060\n",
      "Epoch 7/10\n",
      "29996/29996 [==============================] - 3s 89us/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0063 - val_mean_absolute_error: 0.0063\n",
      "Epoch 8/10\n",
      "29996/29996 [==============================] - 3s 91us/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "Epoch 9/10\n",
      "29996/29996 [==============================] - 3s 94us/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0067 - val_mean_absolute_error: 0.0067\n",
      "Epoch 10/10\n",
      "29996/29996 [==============================] - 3s 92us/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "(0.2090052545751042, 0.7897716977713354, 0.0012230476535604277, [-1.2518422193324663, -3.888888888888889])\n"
     ]
    }
   ],
   "source": [
    "reset_random_seeds(13)\n",
    "for i in [0.2, 0.3, 0.34]:\n",
    "    # train set\n",
    "    df_train, df_test = train_test_split(df, test_size=i, random_state=42)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    # test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    NN_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split = 0.3)\n",
    "\n",
    "    X_test_fit = X_test.copy()\n",
    "    X_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    X_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = NN_model.predict(X_test_fit)\n",
    "\n",
    "    p = []\n",
    "    for i in range(len(preds)):\n",
    "        p.append(preds[i][0])\n",
    "    print(evaluate(df_test, X_test, data, sent_open_hour_range, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e54199",
   "metadata": {},
   "source": [
    "### k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de724ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41553 samples, validate on 10389 samples\n",
      "Epoch 1/10\n",
      "41553/41553 [==============================] - 11s 257us/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 2/10\n",
      "41553/41553 [==============================] - 11s 259us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
      "Epoch 3/10\n",
      "41553/41553 [==============================] - 11s 272us/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "Epoch 4/10\n",
      "41553/41553 [==============================] - 11s 255us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 5/10\n",
      "41553/41553 [==============================] - 12s 279us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 6/10\n",
      "41553/41553 [==============================] - 10s 251us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 7/10\n",
      "41553/41553 [==============================] - 11s 256us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
      "Epoch 8/10\n",
      "41553/41553 [==============================] - 11s 268us/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0055 - val_mean_absolute_error: 0.0055\n",
      "Epoch 9/10\n",
      "41553/41553 [==============================] - 11s 262us/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 10/10\n",
      "41553/41553 [==============================] - 12s 282us/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0055 - val_mean_absolute_error: 0.0055\n",
      "Train on 41553 samples, validate on 10389 samples\n",
      "Epoch 1/10\n",
      "41553/41553 [==============================] - 10s 245us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
      "Epoch 2/10\n",
      "41553/41553 [==============================] - 11s 269us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 3/10\n",
      "41553/41553 [==============================] - 11s 256us/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0052 - val_mean_absolute_error: 0.0052\n",
      "Epoch 4/10\n",
      "41553/41553 [==============================] - 11s 261us/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
      "Epoch 5/10\n",
      "41553/41553 [==============================] - 11s 261us/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0063 - val_mean_absolute_error: 0.0063\n",
      "Epoch 6/10\n",
      "41553/41553 [==============================] - 11s 259us/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0063 - val_mean_absolute_error: 0.0063\n",
      "Epoch 7/10\n",
      "41553/41553 [==============================] - 10s 236us/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 8/10\n",
      "41553/41553 [==============================] - 11s 261us/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0058 - val_mean_absolute_error: 0.0058\n",
      "Epoch 9/10\n",
      "41553/41553 [==============================] - 11s 263us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "Epoch 10/10\n",
      "41553/41553 [==============================] - 11s 262us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0048 - val_mean_absolute_error: 0.0048\n",
      "Train on 41553 samples, validate on 10389 samples\n",
      "Epoch 1/10\n",
      "41553/41553 [==============================] - 11s 271us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
      "Epoch 2/10\n",
      "41553/41553 [==============================] - 11s 272us/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 3/10\n",
      "41553/41553 [==============================] - 11s 271us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 4/10\n",
      "41553/41553 [==============================] - 11s 268us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 5/10\n",
      "41553/41553 [==============================] - 12s 294us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 6/10\n",
      "41553/41553 [==============================] - 11s 260us/step - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 7/10\n",
      "41553/41553 [==============================] - 11s 270us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 8/10\n",
      "41553/41553 [==============================] - 11s 267us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "Epoch 9/10\n",
      "41553/41553 [==============================] - 11s 263us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0051 - val_mean_absolute_error: 0.0051\n",
      "Epoch 10/10\n",
      "41553/41553 [==============================] - 11s 257us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Train on 41554 samples, validate on 10389 samples\n",
      "Epoch 1/10\n",
      "41554/41554 [==============================] - 12s 284us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0048 - val_mean_absolute_error: 0.0048\n",
      "Epoch 2/10\n",
      "41554/41554 [==============================] - 12s 277us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 3/10\n",
      "41554/41554 [==============================] - 11s 267us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 4/10\n",
      "41554/41554 [==============================] - 11s 274us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0056 - val_mean_absolute_error: 0.0056\n",
      "Epoch 5/10\n",
      "41554/41554 [==============================] - 12s 284us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0051 - val_mean_absolute_error: 0.0051\n",
      "Epoch 6/10\n",
      "41554/41554 [==============================] - 12s 284us/step - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "Epoch 7/10\n",
      "41554/41554 [==============================] - 11s 257us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 8/10\n",
      "41554/41554 [==============================] - 12s 278us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0052 - val_mean_absolute_error: 0.0052\n",
      "Epoch 9/10\n",
      "41554/41554 [==============================] - 12s 278us/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0048 - val_mean_absolute_error: 0.0048\n",
      "Epoch 10/10\n",
      "41554/41554 [==============================] - 11s 269us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0051 - val_mean_absolute_error: 0.0051\n",
      "Train on 41554 samples, validate on 10389 samples\n",
      "Epoch 1/10\n",
      "41554/41554 [==============================] - 12s 277us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "Epoch 2/10\n",
      "41554/41554 [==============================] - 11s 276us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0051 - val_mean_absolute_error: 0.0051\n",
      "Epoch 3/10\n",
      "41554/41554 [==============================] - 11s 276us/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
      "Epoch 4/10\n",
      "41554/41554 [==============================] - 11s 273us/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
      "Epoch 5/10\n",
      "41554/41554 [==============================] - 12s 294us/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 6/10\n",
      "41554/41554 [==============================] - 11s 266us/step - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 7/10\n",
      "41554/41554 [==============================] - 12s 280us/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0052 - val_mean_absolute_error: 0.0052\n",
      "Epoch 8/10\n",
      "41554/41554 [==============================] - 12s 292us/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 9/10\n",
      "41554/41554 [==============================] - 11s 274us/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 10/10\n",
      "41554/41554 [==============================] - 11s 269us/step - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08269224503554404, 0.9098226311787091, 0.0074851237857469334)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = X.copy()\n",
    "g = y.copy()\n",
    "res = []\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "for train_index, test_index in kf.split(M):\n",
    "    M_train, M_test = M.iloc[train_index], M.iloc[test_index]\n",
    "    g_train, g_test = g.iloc[train_index], g.iloc[test_index]\n",
    "    \n",
    "    model = NN_model\n",
    "    model.fit(M_train, g_train, epochs=10, batch_size=32, validation_split = 0.2)\n",
    "\n",
    "    M_test_fit = M_test.copy()\n",
    "    M_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    M_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    \n",
    "    preds = model.predict(M_test_fit)\n",
    "    my_df = df.iloc[test_index]\n",
    "    my_df.reset_index(drop=True, inplace=True)\n",
    "    M_test.reset_index(drop=True, inplace=True)\n",
    "    p = []\n",
    "    for i in range(len(preds)):\n",
    "        p.append(preds[i][0])\n",
    "    res.append(evaluate(my_df, M_test, data, sent_open_hour_range, p))\n",
    "better = 0\n",
    "equal = 0\n",
    "worst = 0\n",
    "for i in range(5):\n",
    "    better += res[i][0]\n",
    "    equal += res[i][1]\n",
    "    worst += res[i][2]\n",
    "better/5, equal/5, worst/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94b702",
   "metadata": {},
   "source": [
    "### Lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d40752dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41553 samples, validate on 10389 samples\n",
      "Epoch 1/10\n",
      "41553/41553 [==============================] - 6s 154us/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
      "Epoch 2/10\n",
      "41553/41553 [==============================] - 7s 158us/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0061 - val_mean_absolute_error: 0.0061\n",
      "Epoch 3/10\n",
      "41553/41553 [==============================] - 7s 157us/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0045 - val_mean_absolute_error: 0.0045\n",
      "Epoch 4/10\n",
      "41553/41553 [==============================] - 8s 202us/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
      "Epoch 5/10\n",
      "41553/41553 [==============================] - 7s 161us/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0041 - val_mean_absolute_error: 0.0041\n",
      "Epoch 6/10\n",
      "41553/41553 [==============================] - 6s 154us/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0045 - val_mean_absolute_error: 0.0045\n",
      "Epoch 7/10\n",
      "41553/41553 [==============================] - 7s 157us/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 8/10\n",
      "41553/41553 [==============================] - 7s 157us/step - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 9/10\n",
      "41553/41553 [==============================] - 6s 155us/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 10/10\n",
      "41553/41553 [==============================] - 6s 154us/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0043 - val_mean_absolute_error: 0.0043\n",
      "(0.2065301093485292, 0.7925458185738488, 0.0009240720776220545, [2.6547352721849364, -2.3333333333333335])\n",
      "Train on 36359 samples, validate on 9090 samples\n",
      "Epoch 1/10\n",
      "36359/36359 [==============================] - 6s 157us/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0047 - val_mean_absolute_error: 0.0047\n",
      "Epoch 2/10\n",
      "36359/36359 [==============================] - 6s 158us/step - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 3/10\n",
      "36359/36359 [==============================] - 6s 158us/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0067 - val_mean_absolute_error: 0.0067\n",
      "Epoch 4/10\n",
      "36359/36359 [==============================] - 6s 160us/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0043 - val_mean_absolute_error: 0.0043\n",
      "Epoch 5/10\n",
      "36359/36359 [==============================] - 6s 156us/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0045 - val_mean_absolute_error: 0.0045\n",
      "Epoch 6/10\n",
      "36359/36359 [==============================] - 6s 155us/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0047 - val_mean_absolute_error: 0.0047\n",
      "Epoch 7/10\n",
      "36359/36359 [==============================] - 6s 158us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0043 - val_mean_absolute_error: 0.0043\n",
      "Epoch 8/10\n",
      "36359/36359 [==============================] - 6s 158us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0044 - val_mean_absolute_error: 0.0044\n",
      "Epoch 9/10\n",
      "36359/36359 [==============================] - 6s 157us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0045 - val_mean_absolute_error: 0.0045\n",
      "Epoch 10/10\n",
      "36359/36359 [==============================] - 6s 156us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0044 - val_mean_absolute_error: 0.0044\n",
      "(0.20812156681554494, 0.7910570357821244, 0.0008213974023307152, [-0.6329551060680809, 1.1875])\n",
      "Train on 34282 samples, validate on 8571 samples\n",
      "Epoch 1/10\n",
      "34282/34282 [==============================] - 5s 155us/step - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0045 - val_mean_absolute_error: 0.0045\n",
      "Epoch 2/10\n",
      "34282/34282 [==============================] - 5s 158us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0064 - val_mean_absolute_error: 0.0064\n",
      "Epoch 3/10\n",
      "34282/34282 [==============================] - 6s 163us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0041 - val_mean_absolute_error: 0.0041\n",
      "Epoch 4/10\n",
      "34282/34282 [==============================] - 6s 163us/step - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0042 - val_mean_absolute_error: 0.0042\n",
      "Epoch 5/10\n",
      "34282/34282 [==============================] - 5s 160us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0044 - val_mean_absolute_error: 0.0044\n",
      "Epoch 6/10\n",
      "34282/34282 [==============================] - 5s 156us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0046 - val_mean_absolute_error: 0.0046\n",
      "Epoch 7/10\n",
      "34282/34282 [==============================] - 5s 155us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0046 - val_mean_absolute_error: 0.0046\n",
      "Epoch 8/10\n",
      "34282/34282 [==============================] - 5s 156us/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0044 - val_mean_absolute_error: 0.0044\n",
      "Epoch 9/10\n",
      "34282/34282 [==============================] - 5s 157us/step - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0042 - val_mean_absolute_error: 0.0042\n",
      "Epoch 10/10\n",
      "34282/34282 [==============================] - 5s 153us/step - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
      "(0.20634201585503964, 0.7922536806342015, 0.0014043035107587768, [-6.715477497255763, -5.32258064516129])\n"
     ]
    }
   ],
   "source": [
    "for i in [0.2, 0.3, 0.34]:\n",
    "    X_train, X_test, y_train, y_test, df_train, df_test = split_train_test_by_lifetime(X, df, data, test_size=i, random_seed=42)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    model = NN_model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split = 0.2)\n",
    "\n",
    "\n",
    "    X_test_fit = X_test.copy()\n",
    "    X_test_fit.loc[:, 'fitSA'] = 1 # fitSA\n",
    "    X_test_fit.loc[:, 'fitAC'] = 1 # fitAC\n",
    "    preds = NN_model.predict(X_test_fit)\n",
    "\n",
    "    p = []\n",
    "    for i in range(len(preds)):\n",
    "        p.append(preds[i][0])\n",
    "    print(evaluate(df_test, X_test, data, sent_open_hour_range, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3371f383",
   "metadata": {},
   "source": [
    "## Regression with CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3206ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, sys, numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras import losses\n",
    "from keras import backend as K \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import metrics\n",
    "from keras import models, layers, optimizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b65f014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "59e3b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z['fitSA_copy'] = Z['fitSA']\n",
    "Z['fitAC_copy'] = Z['fitAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ee7da7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 10, 10, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 5, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 5, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 46,497\n",
      "Trainable params: 45,729\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "droprate=0.25\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(10, 10, 1), activation=\"relu\")) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(droprate))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "\n",
    "def rmsle(y_test, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(K.log(y_pred) - K.log(y_test))))\n",
    "\n",
    "model.compile(loss= 'mean_squared_error', optimizer='adam', metrics=[rmsle])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d58f051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "# test set\n",
    "Z_train, Z_test, y_train, y_test = train_test_split(Z, y, test_size=0.33, random_state=42)\n",
    "Z_train.reset_index(drop=True, inplace=True)\n",
    "Z_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# test set\n",
    "X_train, X_test, g_train, g_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "62b2391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([])\n",
    "for i in range(len(Z_train)):\n",
    "    row = Z_train.iloc[i, :].to_numpy().reshape(-1, 1).reshape(10, 10, 1)\n",
    "    arr = np.append(arr, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "81170455",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([])\n",
    "for i in range(len(Z_test)):\n",
    "    row = Z_test.iloc[i, :].to_numpy().reshape(-1, 1).reshape(10, 10, 1)\n",
    "    arr2 = np.append(arr2, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c14c2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train_img = arr.reshape(Z_train.shape[0], 10, 10, 1)\n",
    "Z_test_img = arr2.reshape(Z_test.shape[0], 10, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c1613ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30450 samples, validate on 13051 samples\n",
      "Epoch 1/10\n",
      "30450/30450 [==============================] - 19s 610us/step - loss: 0.1342 - rmsle: nan - val_loss: 0.0070 - val_rmsle: 0.1554\n",
      "Epoch 2/10\n",
      "30450/30450 [==============================] - 14s 468us/step - loss: 0.0133 - rmsle: nan - val_loss: 0.0098 - val_rmsle: 0.1985\n",
      "Epoch 3/10\n",
      "30450/30450 [==============================] - 14s 468us/step - loss: 0.0077 - rmsle: nan - val_loss: 0.0042 - val_rmsle: 0.1227\n",
      "Epoch 4/10\n",
      "30450/30450 [==============================] - 15s 480us/step - loss: 0.0056 - rmsle: 0.1449 - val_loss: 0.0020 - val_rmsle: 0.0839\n",
      "Epoch 5/10\n",
      "30450/30450 [==============================] - 14s 468us/step - loss: 0.0048 - rmsle: 0.1341 - val_loss: 0.0019 - val_rmsle: 0.0843\n",
      "Epoch 6/10\n",
      "30450/30450 [==============================] - 14s 465us/step - loss: 0.0037 - rmsle: 0.1187 - val_loss: 0.0065 - val_rmsle: 0.1613\n",
      "Epoch 7/10\n",
      "30450/30450 [==============================] - 14s 465us/step - loss: 0.0030 - rmsle: 0.1052 - val_loss: 0.0012 - val_rmsle: 0.0644\n",
      "Epoch 8/10\n",
      "30450/30450 [==============================] - 14s 467us/step - loss: 0.0026 - rmsle: 0.0990 - val_loss: 0.0025 - val_rmsle: 0.0986\n",
      "Epoch 9/10\n",
      "30450/30450 [==============================] - 15s 478us/step - loss: 0.0022 - rmsle: 0.0904 - val_loss: 0.0022 - val_rmsle: 0.0895\n",
      "Epoch 10/10\n",
      "30450/30450 [==============================] - 14s 469us/step - loss: 0.0020 - rmsle: 0.0852 - val_loss: 0.0022 - val_rmsle: 0.0869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff7f58def28>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Z_train_img, y_train, batch_size=64, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "80220a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_test_img_fit = Z_test_img.copy()\n",
    "Z_test_img_fit[:, 9, 8, 0] = 1 # fitSA\n",
    "Z_test_img_fit[:, 9, 9, 0] = 1 # fitAC\n",
    "preds = model.predict(Z_test_img_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d66df351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6783531 ],\n",
       "       [0.62115383],\n",
       "       [0.4813221 ],\n",
       "       ...,\n",
       "       [0.4718498 ],\n",
       "       [0.63246495],\n",
       "       [0.64637977]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eea3eb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1385634946562748, 0.8544359919727447, 0.007000513370980539)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "for i in range(len(preds)):\n",
    "    p.append(preds[i][0])\n",
    "evaluate(df_test, X_test, data, sent_open_hour_range, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f66de",
   "metadata": {},
   "source": [
    "**never_opened=False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ff47ed9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5866429559375618, 0.06915629322268327, 0.344200750839755)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "for i in range(len(preds)):\n",
    "    p.append(preds[i][0])\n",
    "evaluate(df_test, X_test, data, sent_open_hour_range, p, never_opened=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ee2064",
   "metadata": {},
   "source": [
    "### k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7c9705d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36359 samples, validate on 15583 samples\n",
      "Epoch 1/10\n",
      "36359/36359 [==============================] - 17s 476us/step - loss: 3.1505e-04 - rmsle: 0.0308 - val_loss: 0.0011 - val_rmsle: 0.0789\n",
      "Epoch 2/10\n",
      "36359/36359 [==============================] - 17s 469us/step - loss: 3.3090e-04 - rmsle: 0.0317 - val_loss: 2.7236e-04 - val_rmsle: 0.0304\n",
      "Epoch 3/10\n",
      "36359/36359 [==============================] - 17s 461us/step - loss: 3.1987e-04 - rmsle: 0.0310 - val_loss: 6.5010e-04 - val_rmsle: 0.0577\n",
      "Epoch 4/10\n",
      "36359/36359 [==============================] - 20s 539us/step - loss: 3.3280e-04 - rmsle: 0.0319 - val_loss: 1.7149e-04 - val_rmsle: 0.0203\n",
      "Epoch 5/10\n",
      "36359/36359 [==============================] - 19s 511us/step - loss: 3.1000e-04 - rmsle: 0.0304 - val_loss: 0.0011 - val_rmsle: 0.0655\n",
      "Epoch 6/10\n",
      "36359/36359 [==============================] - 19s 523us/step - loss: 3.5192e-04 - rmsle: 0.0334 - val_loss: 2.1085e-04 - val_rmsle: 0.0245\n",
      "Epoch 7/10\n",
      "36359/36359 [==============================] - 19s 511us/step - loss: 3.1463e-04 - rmsle: 0.0304 - val_loss: 2.2323e-04 - val_rmsle: 0.0261\n",
      "Epoch 8/10\n",
      "36359/36359 [==============================] - 18s 504us/step - loss: 3.2248e-04 - rmsle: 0.0309 - val_loss: 2.6085e-04 - val_rmsle: 0.0309\n",
      "Epoch 9/10\n",
      "36359/36359 [==============================] - 19s 516us/step - loss: 3.1890e-04 - rmsle: 0.0308 - val_loss: 0.0015 - val_rmsle: 0.0961\n",
      "Epoch 10/10\n",
      "36359/36359 [==============================] - 18s 503us/step - loss: 3.2928e-04 - rmsle: 0.0317 - val_loss: 2.1287e-04 - val_rmsle: 0.0258\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data '24:31' does not match format '%H:%M' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mdta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-44a4e57eb982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmy_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mM_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_open_hour_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mbetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mequal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-5c736356ef4e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(df, X, data, sent_open_hour_range, preds, never_opened)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mfitSC_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mfitSA_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_fitSA_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashMessaggio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashContatto'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_open_hour_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnever_opened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mfitSC_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_fitSC_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashMessaggio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HashContatto'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_open_hour_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnever_opened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-5c736356ef4e>\u001b[0m in \u001b[0;36mcompute_fitSA_evaluation\u001b[0;34m(hash_mex, hash_contact, sent_open_hour_range, data, sent_pred, never_opened)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0moldest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0moldest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%H:%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0msent_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%H:%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;31m# compute minutes of the distance between sent-open/sent-click\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mmins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldest\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msent_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldest\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msent_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldest\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msent_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                     result, timezones = array_strptime(\n\u001b[0;32m--> 418\u001b[0;31m                         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                     )\n\u001b[1;32m    420\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"%Z\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"%z\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data '24:31' does not match format '%H:%M' (match)"
     ]
    }
   ],
   "source": [
    "M = Z.copy()\n",
    "g = y.copy()\n",
    "res = []\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "for train_index, test_index in kf.split(M):\n",
    "    M_train, M_test = M.iloc[train_index], M.iloc[test_index]\n",
    "    g_train, g_test = g.iloc[train_index], g.iloc[test_index]\n",
    "    \n",
    "    arr = np.array([])\n",
    "    for i in range(len(M_train)):\n",
    "        row = M_train.iloc[i, :].to_numpy().reshape(-1, 1).reshape(10, 10, 1)\n",
    "        arr = np.append(arr, row)\n",
    "    \n",
    "    arr2 = np.array([])\n",
    "    for i in range(len(M_test)):\n",
    "        row = M_test.iloc[i, :].to_numpy().reshape(-1, 1).reshape(10, 10, 1)\n",
    "        arr2 = np.append(arr2, row)\n",
    "    \n",
    "    M_train_img = arr.reshape(M_train.shape[0], 10, 10, 1)\n",
    "    M_test_img = arr2.reshape(M_test.shape[0], 10, 10, 1)\n",
    "    \n",
    "    model.fit(M_train_img, g_train, batch_size=64, epochs=10, validation_split=0.3)\n",
    "    \n",
    "    M_test_img_fit = M_test_img.copy()\n",
    "    M_test_img_fit[:, 9, 8, 0] = 1 # fitSA\n",
    "    M_test_img_fit[:, 9, 9, 0] = 1 # fitAC\n",
    "    preds = model.predict(M_test_img_fit)\n",
    "    \n",
    "    p = []\n",
    "    for i in range(len(preds)):\n",
    "        p.append(preds[i][0])\n",
    "    \n",
    "    my_df = df.iloc[test_index]\n",
    "    my_df.reset_index(drop=True, inplace=True)\n",
    "    M_test.reset_index(drop=True, inplace=True)\n",
    "    res.append(evaluate(my_df, M_test, data, sent_open_hour_range, p, never_opened=False))\n",
    "better = 0\n",
    "equal = 0\n",
    "worst = 0\n",
    "for i in range(5):\n",
    "    better += res[i][0]\n",
    "    equal += res[i][1]\n",
    "    worst += res[i][2]\n",
    "better/5, equal/5, worst/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6ba59b",
   "metadata": {},
   "source": [
    "### Lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f8ba1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.copy()\n",
    "Z['fitSA_copy'] = Z['fitSA']\n",
    "Z['fitAC_copy'] = Z['fitAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0efaebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "Z_train, Z_test, y_train, y_test, df_train, df_test = split_train_test_by_lifetime(Z, df, data, test_size=0.34, random_seed=42)\n",
    "Z_train.reset_index(drop=True, inplace=True)\n",
    "Z_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "13d74c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([])\n",
    "for i in range(len(Z_train)):\n",
    "    row = Z_train.iloc[i, :].to_numpy().reshape(-1, 1).reshape(10, 10, 1)\n",
    "    arr = np.append(arr, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d7aa1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([])\n",
    "for i in range(len(Z_test)):\n",
    "    row = Z_test.iloc[i, :].to_numpy().reshape(-1, 1).reshape(10, 10, 1)\n",
    "    arr2 = np.append(arr2, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1096c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train_img = arr.reshape(Z_train.shape[0], 10, 10, 1)\n",
    "Z_test_img = arr2.reshape(Z_test.shape[0], 10, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c1e67835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29997 samples, validate on 12856 samples\n",
      "Epoch 1/10\n",
      "29997/29997 [==============================] - 16s 537us/step - loss: 2.9557e-04 - rmsle: 0.0292 - val_loss: 1.8143e-04 - val_rmsle: 0.0227\n",
      "Epoch 2/10\n",
      "29997/29997 [==============================] - 14s 478us/step - loss: 2.9775e-04 - rmsle: 0.0292 - val_loss: 2.2000e-04 - val_rmsle: 0.0254\n",
      "Epoch 3/10\n",
      "29997/29997 [==============================] - 14s 464us/step - loss: 2.9674e-04 - rmsle: 0.0293 - val_loss: 1.6447e-04 - val_rmsle: 0.0203\n",
      "Epoch 4/10\n",
      "29997/29997 [==============================] - 14s 461us/step - loss: 2.9423e-04 - rmsle: 0.0288 - val_loss: 2.4384e-04 - val_rmsle: 0.0276\n",
      "Epoch 5/10\n",
      "29997/29997 [==============================] - 14s 457us/step - loss: 3.3523e-04 - rmsle: 0.0307 - val_loss: 6.3837e-04 - val_rmsle: 0.0562\n",
      "Epoch 6/10\n",
      "29997/29997 [==============================] - 14s 455us/step - loss: 3.1633e-04 - rmsle: 0.0302 - val_loss: 1.5646e-04 - val_rmsle: 0.0201\n",
      "Epoch 7/10\n",
      "29997/29997 [==============================] - 14s 456us/step - loss: 2.9157e-04 - rmsle: 0.0288 - val_loss: 1.6206e-04 - val_rmsle: 0.0205\n",
      "Epoch 8/10\n",
      "29997/29997 [==============================] - 14s 471us/step - loss: 3.6894e-04 - rmsle: 0.0320 - val_loss: 1.9682e-04 - val_rmsle: 0.0219\n",
      "Epoch 9/10\n",
      "29997/29997 [==============================] - 14s 460us/step - loss: 3.0974e-04 - rmsle: 0.0299 - val_loss: 1.5273e-04 - val_rmsle: 0.0197\n",
      "Epoch 10/10\n",
      "29997/29997 [==============================] - 14s 452us/step - loss: 2.9600e-04 - rmsle: 0.0290 - val_loss: 1.5393e-04 - val_rmsle: 0.0194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff7dbffad68>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Z_train_img, y_train, batch_size=64, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "873f87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_test_img_fit = Z_test_img.copy()\n",
    "Z_test_img_fit[:, 9, 8, 0] = 1 # fitSA\n",
    "Z_test_img_fit[:, 9, 9, 0] = 1 # fitAC\n",
    "preds = model.predict(Z_test_img_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "81086bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, df_train, df_test = split_train_test_by_lifetime(X, df, data, test_size=0.34, random_seed=42)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "66cf2a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11823329558323896, 0.8774178935447339, 0.00434881087202718)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "for i in range(len(preds)):\n",
    "    p.append(preds[i][0])\n",
    "evaluate(df_test, X_test, data, sent_open_hour_range, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ddc873",
   "metadata": {},
   "source": [
    "**never_opened=False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3eace757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5006713984270094, 0.12142720122769998, 0.37790140034529063)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "for i in range(len(preds)):\n",
    "    p.append(preds[i][0])\n",
    "evaluate(df_test, X_test, data, sent_open_hour_range, p, never_opened=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vedere se altri modelli tipo cnn danno orari molto diversi tra loro o se smili come least angle regr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
